{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 2. Working with large datasets faster: parallelization and the map function\n",
    "====\n",
    "### Mastering Large Datasets with Python by JT Wolohan \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 2.1 and 2.2 :: Formatting phone numbers with loops and maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class PhoneFormatter:\n",
    "    def __init__(self):\n",
    "        self.r = re.compile(r\"\\d\")\n",
    "        \n",
    "    def pretty_format(self, phone_number):\n",
    "        numbers = self.r.findall(phone_number)\n",
    "        area_code = \"\".join(numbers[-10:-7])\n",
    "        first_3 = \"\".join(numbers[-7:-4])\n",
    "        last_4 = \"\".join(numbers[-4:len(numbers)])\n",
    "        return \"({}) {}-{}\".format(area_code, first_3, last_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_numbers = [\n",
    "    \"(123) 456-7890\",\n",
    "    \"1234567890\",\n",
    "    \"123.456.7890\",\n",
    "    \"+1 123 456-7890\"\n",
    "]\n",
    "\n",
    "P = PhoneFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_numbers = []\n",
    "for phone_number in phone_numbers:\n",
    "    pretty = P.pretty_format(phone_number)\n",
    "    clean_numbers.append(pretty)\n",
    "print(clean_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(map(P.pretty_format, phone_numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel blog processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from urllib import request\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def days_between(start,stop):\n",
    "  today = date(*start)\n",
    "  stop = date(*stop)\n",
    "  while today < stop:\n",
    "    datestr = today.strftime(\"%m-%d-%Y\")\n",
    "    yield \"http://jtwolohan.com/arch-rival-blog/\"+datestr\n",
    "    today = date.fromordinal(today.toordinal()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(path):\n",
    "  return request.urlopen(path).read()\n",
    "\n",
    "with Pool() as P:\n",
    "  blog_posts = P.map(get_url,days_between((2000,1,1),(2011,1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fizz Buzz - state and parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FizzBuzzer:\n",
    "  def __init__(self):\n",
    "    self.n = 0\n",
    "  def foo(self,_):\n",
    "    self.n += 1\n",
    "    if (self.n % 3)  == 0:\n",
    "      x = \"buzz\"\n",
    "    else: x = \"fizz\"\n",
    "    print(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = FizzBuzzer()\n",
    "for i in range(21):\n",
    "  FB.foo(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool() as P:\n",
    "    P.map(FB.foo, range(1,22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib import request, parse\n",
    "from multiprocessing import Pool\n",
    "from itertools import chain\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_title(link):\n",
    "  return link[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_if_key(page,key):\n",
    "    if key in page.keys():\n",
    "        return map(link_to_title,page[key])\n",
    "    else: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Wiki_links(pageTitle):\n",
    "    safe_title = parse.quote(pageTitle)\n",
    "    url = \"https://en.wikipedia.org/w/api.php?action=query&\\\n",
    "prop=links|linkshere&pllimit=500&lhlimit=500&titles={}&\\\n",
    "format=json&formatversion=2\".format(safe_title)\n",
    "    page = request.urlopen(url).read().decode('utf-8')\n",
    "    j = json.loads(page)\n",
    "    jpage = j['query']['pages'][0]\n",
    "    inbound = clean_if_key(jpage,\"links\")\n",
    "    outbound = clean_if_key(jpage,\"linkshere\")\n",
    "    return {\"title\": pageTitle,\n",
    "            \"in-links\":list(inbound),\n",
    "            \"out-links\":list(outbound)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_network(page):\n",
    "    return page[\"in-links\"]+page[\"out-links\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_to_edges(page):\n",
    "    a = [(page['title'],p) for p in page['out-links']]\n",
    "    b = [(p,page['title']) for p in page['in-links']]\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = get_Wiki_links(\"Parallel_computing\")\n",
    "initial_network = flatten_network(root)\n",
    "with Pool() as P:\n",
    "    all_pages = P.map(get_Wiki_links, initial_network)\n",
    "    edges = P.map(page_to_edges, all_pages)\n",
    "edges = chain.from_iterable(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for e in edges:\n",
    "    G.add_edge(*e)\n",
    "nx.readwrite.gexf.write_gexf(G,\"./MyGraph.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Read for more? Go to chapter 3!](./Ch03_notebook.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldbook",
   "language": "python",
   "name": "mldbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
